{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d4f8579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be83e835",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/mac/Developer/Data Science Project/data/customer_training_dataset.csv',nrows=10000)\n",
    "df = df.iloc[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89d02be2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Annual Income</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Number of Dependents</th>\n",
       "      <th>Education Level</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Health Score</th>\n",
       "      <th>Location</th>\n",
       "      <th>Policy Type</th>\n",
       "      <th>Previous Claims</th>\n",
       "      <th>Vehicle Age</th>\n",
       "      <th>Credit Score</th>\n",
       "      <th>Insurance Duration</th>\n",
       "      <th>Policy Start Date</th>\n",
       "      <th>Customer Feedback</th>\n",
       "      <th>Smoking Status</th>\n",
       "      <th>Exercise Frequency</th>\n",
       "      <th>Property Type</th>\n",
       "      <th>Premium Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.0</td>\n",
       "      <td>Woman</td>\n",
       "      <td>10049.0</td>\n",
       "      <td>Spouse Present</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>Freelancer</td>\n",
       "      <td>22.598761</td>\n",
       "      <td>City</td>\n",
       "      <td>Premium</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2023-12-23 15:21:39.134960</td>\n",
       "      <td>Poor</td>\n",
       "      <td>No</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>Detached Home</td>\n",
       "      <td>2869.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.0</td>\n",
       "      <td>Woman</td>\n",
       "      <td>31678.0</td>\n",
       "      <td>Formerly Married</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.569731</td>\n",
       "      <td>Country</td>\n",
       "      <td>Comprehensive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>694.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2023-06-12 15:21:39.111551</td>\n",
       "      <td>Average</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>Detached Home</td>\n",
       "      <td>1483.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.0</td>\n",
       "      <td>Man</td>\n",
       "      <td>25602.0</td>\n",
       "      <td>Formerly Married</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Secondary Education</td>\n",
       "      <td>Freelancer</td>\n",
       "      <td>47.177549</td>\n",
       "      <td>Countryside</td>\n",
       "      <td>Premium</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2023-09-30 15:21:39.221386</td>\n",
       "      <td>Good</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>Detached Home</td>\n",
       "      <td>567.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.0</td>\n",
       "      <td>Man</td>\n",
       "      <td>141855.0</td>\n",
       "      <td>Spouse Present</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.938144</td>\n",
       "      <td>Country</td>\n",
       "      <td>Basic</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>367.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2024-06-12 15:21:39.226954</td>\n",
       "      <td>Poor</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Daily</td>\n",
       "      <td>Flat</td>\n",
       "      <td>765.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21.0</td>\n",
       "      <td>Man</td>\n",
       "      <td>39651.0</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>Freelancer</td>\n",
       "      <td>20.376094</td>\n",
       "      <td>Country</td>\n",
       "      <td>Premium</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>598.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2021-12-01 15:21:39.252145</td>\n",
       "      <td>Poor</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>Detached Home</td>\n",
       "      <td>2022.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age Gender  Annual Income    Marital Status  Number of Dependents  \\\n",
       "0  19.0  Woman        10049.0    Spouse Present                   1.0   \n",
       "1  39.0  Woman        31678.0  Formerly Married                   3.0   \n",
       "2  23.0    Man        25602.0  Formerly Married                   3.0   \n",
       "3  21.0    Man       141855.0    Spouse Present                   2.0   \n",
       "4  21.0    Man        39651.0       Not Married                   1.0   \n",
       "\n",
       "       Education Level  Occupation  Health Score     Location    Policy Type  \\\n",
       "0        Undergraduate  Freelancer     22.598761         City        Premium   \n",
       "1             Graduate         NaN     15.569731      Country  Comprehensive   \n",
       "2  Secondary Education  Freelancer     47.177549  Countryside        Premium   \n",
       "3        Undergraduate         NaN     10.938144      Country          Basic   \n",
       "4        Undergraduate  Freelancer     20.376094      Country        Premium   \n",
       "\n",
       "   Previous Claims  Vehicle Age  Credit Score  Insurance Duration  \\\n",
       "0              2.0         17.0         372.0                 5.0   \n",
       "1              1.0         12.0         694.0                 2.0   \n",
       "2              1.0         14.0           NaN                 3.0   \n",
       "3              1.0          0.0         367.0                 1.0   \n",
       "4              0.0          8.0         598.0                 4.0   \n",
       "\n",
       "            Policy Start Date Customer Feedback Smoking Status  \\\n",
       "0  2023-12-23 15:21:39.134960              Poor             No   \n",
       "1  2023-06-12 15:21:39.111551           Average            Yes   \n",
       "2  2023-09-30 15:21:39.221386              Good            Yes   \n",
       "3  2024-06-12 15:21:39.226954              Poor            Yes   \n",
       "4  2021-12-01 15:21:39.252145              Poor            Yes   \n",
       "\n",
       "  Exercise Frequency  Property Type  Premium Amount  \n",
       "0             Weekly  Detached Home          2869.0  \n",
       "1            Monthly  Detached Home          1483.0  \n",
       "2             Weekly  Detached Home           567.0  \n",
       "3              Daily           Flat           765.0  \n",
       "4             Weekly  Detached Home          2022.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bd648a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Annual Income</th>\n",
       "      <th>Education Level</th>\n",
       "      <th>Location</th>\n",
       "      <th>Policy Type</th>\n",
       "      <th>Customer Feedback</th>\n",
       "      <th>Property Type</th>\n",
       "      <th>Premium Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.0</td>\n",
       "      <td>Woman</td>\n",
       "      <td>10049.0</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>City</td>\n",
       "      <td>Premium</td>\n",
       "      <td>Poor</td>\n",
       "      <td>Detached Home</td>\n",
       "      <td>2869.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.0</td>\n",
       "      <td>Woman</td>\n",
       "      <td>31678.0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Country</td>\n",
       "      <td>Comprehensive</td>\n",
       "      <td>Average</td>\n",
       "      <td>Detached Home</td>\n",
       "      <td>1483.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.0</td>\n",
       "      <td>Man</td>\n",
       "      <td>25602.0</td>\n",
       "      <td>Secondary Education</td>\n",
       "      <td>Countryside</td>\n",
       "      <td>Premium</td>\n",
       "      <td>Good</td>\n",
       "      <td>Detached Home</td>\n",
       "      <td>567.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.0</td>\n",
       "      <td>Man</td>\n",
       "      <td>141855.0</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>Country</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Poor</td>\n",
       "      <td>Flat</td>\n",
       "      <td>765.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21.0</td>\n",
       "      <td>Man</td>\n",
       "      <td>39651.0</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>Country</td>\n",
       "      <td>Premium</td>\n",
       "      <td>Poor</td>\n",
       "      <td>Detached Home</td>\n",
       "      <td>2022.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>33.0</td>\n",
       "      <td>Woman</td>\n",
       "      <td>37223.0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Country</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Poor</td>\n",
       "      <td>Flat</td>\n",
       "      <td>675.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>25.0</td>\n",
       "      <td>Man</td>\n",
       "      <td>34757.0</td>\n",
       "      <td>Secondary Education</td>\n",
       "      <td>Country</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Good</td>\n",
       "      <td>Flat</td>\n",
       "      <td>736.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>36.0</td>\n",
       "      <td>Woman</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>City</td>\n",
       "      <td>Comprehensive</td>\n",
       "      <td>Good</td>\n",
       "      <td>Detached Home</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>41.0</td>\n",
       "      <td>Woman</td>\n",
       "      <td>2750.0</td>\n",
       "      <td>Secondary Education</td>\n",
       "      <td>Country</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Average</td>\n",
       "      <td>Flat</td>\n",
       "      <td>464.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>32.0</td>\n",
       "      <td>Woman</td>\n",
       "      <td>142692.0</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>Countryside</td>\n",
       "      <td>Premium</td>\n",
       "      <td>Poor</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>157.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age Gender  Annual Income      Education Level     Location  \\\n",
       "0     19.0  Woman        10049.0        Undergraduate         City   \n",
       "1     39.0  Woman        31678.0             Graduate      Country   \n",
       "2     23.0    Man        25602.0  Secondary Education  Countryside   \n",
       "3     21.0    Man       141855.0        Undergraduate      Country   \n",
       "4     21.0    Man        39651.0        Undergraduate      Country   \n",
       "...    ...    ...            ...                  ...          ...   \n",
       "9995  33.0  Woman        37223.0             Graduate      Country   \n",
       "9996  25.0    Man        34757.0  Secondary Education      Country   \n",
       "9997  36.0  Woman            NaN        Undergraduate         City   \n",
       "9998  41.0  Woman         2750.0  Secondary Education      Country   \n",
       "9999  32.0  Woman       142692.0        Undergraduate  Countryside   \n",
       "\n",
       "        Policy Type Customer Feedback  Property Type  Premium Amount  \n",
       "0           Premium              Poor  Detached Home          2869.0  \n",
       "1     Comprehensive           Average  Detached Home          1483.0  \n",
       "2           Premium              Good  Detached Home           567.0  \n",
       "3             Basic              Poor           Flat           765.0  \n",
       "4           Premium              Poor  Detached Home          2022.0  \n",
       "...             ...               ...            ...             ...  \n",
       "9995          Basic              Poor           Flat           675.0  \n",
       "9996          Basic              Good           Flat           736.0  \n",
       "9997  Comprehensive              Good  Detached Home           100.0  \n",
       "9998          Basic           Average           Flat           464.0  \n",
       "9999        Premium              Poor      Apartment           157.0  \n",
       "\n",
       "[10000 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['Age','Gender','Annual Income','Education Level','Location','Policy Type','Customer Feedback','Property Type','Premium Amount']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f6af943",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c8d6383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical_feature len is:->[ 2 ] - columns are:->['Age', 'Annual Income']\n",
      "numerical_feature len is:->[ 6 ] - columns are:->['Gender', 'Education Level', 'Location', 'Policy Type', 'Customer Feedback', 'Property Type']\n"
     ]
    }
   ],
   "source": [
    "numerical_feature = [feature for feature in x.columns if x[feature].dtype != \"O\"]\n",
    "categorical_feature = [feature for feature in x.columns if x[feature].dtype == \"O\"]\n",
    "\n",
    "print(f\"numerical_feature len is:->[ {len(numerical_feature)} ] - columns are:->{numerical_feature}\")\n",
    "print(f\"numerical_feature len is:->[ {len(categorical_feature)} ] - columns are:->{categorical_feature}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eadc18d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                  143\n",
       "Gender                 0\n",
       "Annual Income        384\n",
       "Education Level        0\n",
       "Location               0\n",
       "Policy Type            0\n",
       "Customer Feedback    713\n",
       "Property Type          0\n",
       "Premium Amount         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1162e068",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3141ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "501dd754",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline,make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder,OrdinalEncoder,LabelEncoder,RobustScaler,MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc152cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 8) (8000,) (2000, 8) (2000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d5ecc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipe = Pipeline(steps=[\n",
    "    ('num_impute',SimpleImputer(strategy='median')),\n",
    "    ('scaler',MinMaxScaler())\n",
    "])\n",
    "\n",
    "cat_pipe = Pipeline(steps=[\n",
    "    ('cat_impute',SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder',OneHotEncoder(handle_unknown='ignore',drop='first',sparse_output=False))\n",
    "])\n",
    "\n",
    "tranformer = ColumnTransformer([\n",
    "    ('num_trans',num_pipe,numerical_feature),\n",
    "    ('cat_trans',cat_pipe,categorical_feature)\n",
    "],remainder='passthrough',n_jobs=-1)\n",
    "\n",
    "tranformer.fit(X_train)\n",
    "\n",
    "x_train = tranformer.transform(X_train)\n",
    "x_test = tranformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1366d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score is : -0.06949477062406073\n",
      "mean_squared_error is : 749478.3328061312\n",
      "mean_absolute_error is : 628.4206949274791\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import r2_score,mean_absolute_error,mean_squared_error\n",
    "\n",
    "rf = SVR()\n",
    "\n",
    "rf.fit(x_train,y_train)\n",
    "\n",
    "y_pred = rf.predict(x_test)\n",
    "\n",
    "rscore = r2_score(y_test,y_pred)\n",
    "mse = mean_squared_error(y_test,y_pred)\n",
    "mae = mean_absolute_error(y_test,y_pred)\n",
    "\n",
    "\n",
    "print(f\"r2_score is : {rscore}\")\n",
    "print(f\"mean_squared_error is : {mse}\")\n",
    "print(f\"mean_absolute_error is : {mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54c65265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.07139304, -0.0900425 , -0.08297589, -0.11058815, -0.0900608 ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold,cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "kf = KFold(n_splits=5,shuffle=True,random_state=42)\n",
    "cv_result = cross_val_score(estimator=RandomForestRegressor(),X=x_train,y=y_train,cv=kf,n_jobs=-1)\n",
    "cv_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffaefa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-18 15:44:33,127 - 1572159124 - INFO - Proccess are ready to work\n",
      "2025-05-18 15:44:33,219 - 1572159124 - INFO - data are load successfull.\n",
      "2025-05-18 15:44:33,235 - 1572159124 - INFO - spliting train and test.\n",
      "2025-05-18 15:44:33,239 - 1572159124 - INFO - transformation is going on.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape mismatch: if categories is an array, it has to be of shape (n_features,).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31m_RemoteTraceback\u001b[39m                          Traceback (most recent call last)",
      "\u001b[31m_RemoteTraceback\u001b[39m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/mac/Developer/Data Science Project/dsp/lib/python3.13/site-packages/joblib/externals/loky/process_executor.py\", line 490, in _process_worker\n    r = call_item()\n  File \"/Users/mac/Developer/Data Science Project/dsp/lib/python3.13/site-packages/joblib/externals/loky/process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n           ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/mac/Developer/Data Science Project/dsp/lib/python3.13/site-packages/joblib/parallel.py\", line 606, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n            ~~~~^^^^^^^^^^^^^^^^^\n  File \"/Users/mac/Developer/Data Science Project/dsp/lib/python3.13/site-packages/sklearn/utils/parallel.py\", line 139, in __call__\n    return self.function(*args, **kwargs)\n           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Users/mac/Developer/Data Science Project/dsp/lib/python3.13/site-packages/sklearn/pipeline.py\", line 1551, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n  File \"/Users/mac/Developer/Data Science Project/dsp/lib/python3.13/site-packages/sklearn/base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/mac/Developer/Data Science Project/dsp/lib/python3.13/site-packages/sklearn/pipeline.py\", line 730, in fit_transform\n    return last_step.fit_transform(\n           ~~~~~~~~~~~~~~~~~~~~~~~^\n        Xt, y, **last_step_params[\"fit_transform\"]\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/mac/Developer/Data Science Project/dsp/lib/python3.13/site-packages/sklearn/utils/_set_output.py\", line 319, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/mac/Developer/Data Science Project/dsp/lib/python3.13/site-packages/sklearn/base.py\", line 918, in fit_transform\n    return self.fit(X, **fit_params).transform(X)\n           ~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Users/mac/Developer/Data Science Project/dsp/lib/python3.13/site-packages/sklearn/base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/mac/Developer/Data Science Project/dsp/lib/python3.13/site-packages/sklearn/preprocessing/_encoders.py\", line 1515, in fit\n    fit_results = self._fit(\n        X,\n    ...<2 lines>...\n        return_and_ignore_missing_for_infrequent=True,\n    )\n  File \"/Users/mac/Developer/Data Science Project/dsp/lib/python3.13/site-packages/sklearn/preprocessing/_encoders.py\", line 90, in _fit\n    raise ValueError(\n    ...<2 lines>...\n    )\nValueError: Shape mismatch: if categories is an array, it has to be of shape (n_features,).\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[68]\u001b[39m\u001b[32m, line 67\u001b[39m\n\u001b[32m     55\u001b[39m transformer = ColumnTransformer(transformers=[\n\u001b[32m     56\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mnum_pipe\u001b[39m\u001b[33m'\u001b[39m,num_pipe,numerical_columns),\n\u001b[32m     57\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mcat_pipe\u001b[39m\u001b[33m'\u001b[39m,cat_pipe,categorical_columns),\n\u001b[32m   (...)\u001b[39m\u001b[32m     62\u001b[39m remainder=\u001b[33m'\u001b[39m\u001b[33mpassthrough\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     63\u001b[39m n_jobs=-\u001b[32m1\u001b[39m)\n\u001b[32m     65\u001b[39m logging.info(\u001b[33m'\u001b[39m\u001b[33mtransformation is going on.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     69\u001b[39m X_train = transformer.transform(x_train)\n\u001b[32m     70\u001b[39m X_test = transformer.transform(x_test)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/Data Science Project/dsp/lib/python3.13/site-packages/sklearn/compose/_column_transformer.py:947\u001b[39m, in \u001b[36mColumnTransformer.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    944\u001b[39m _raise_for_params(params, \u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    945\u001b[39m \u001b[38;5;66;03m# we use fit_transform to make sure to set sparse_output_ (for which we\u001b[39;00m\n\u001b[32m    946\u001b[39m \u001b[38;5;66;03m# need the transformed data) to have consistent output type in predict\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m947\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/Data Science Project/dsp/lib/python3.13/site-packages/sklearn/utils/_set_output.py:319\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    317\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    321\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    322\u001b[39m         return_tuple = (\n\u001b[32m    323\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    324\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    325\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/Data Science Project/dsp/lib/python3.13/site-packages/sklearn/base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/Data Science Project/dsp/lib/python3.13/site-packages/sklearn/compose/_column_transformer.py:1001\u001b[39m, in \u001b[36mColumnTransformer.fit_transform\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    998\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    999\u001b[39m     routed_params = \u001b[38;5;28mself\u001b[39m._get_empty_routing()\n\u001b[32m-> \u001b[39m\u001b[32m1001\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_func_on_transformers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_fit_transform_one\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumn_as_labels\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result:\n\u001b[32m   1010\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_fitted_transformers([])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/Data Science Project/dsp/lib/python3.13/site-packages/sklearn/compose/_column_transformer.py:910\u001b[39m, in \u001b[36mColumnTransformer._call_func_on_transformers\u001b[39m\u001b[34m(self, X, y, func, column_as_labels, routed_params)\u001b[39m\n\u001b[32m    898\u001b[39m             extra_args = {}\n\u001b[32m    899\u001b[39m         jobs.append(\n\u001b[32m    900\u001b[39m             delayed(func)(\n\u001b[32m    901\u001b[39m                 transformer=clone(trans) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fitted \u001b[38;5;28;01melse\u001b[39;00m trans,\n\u001b[32m   (...)\u001b[39m\u001b[32m    907\u001b[39m             )\n\u001b[32m    908\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m910\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    912\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    913\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mExpected 2D array, got 1D array instead\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/Data Science Project/dsp/lib/python3.13/site-packages/sklearn/utils/parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/Data Science Project/dsp/lib/python3.13/site-packages/joblib/parallel.py:2071\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2065\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2071\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/Data Science Project/dsp/lib/python3.13/site-packages/joblib/parallel.py:1681\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1678\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1680\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1681\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1683\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1684\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/Data Science Project/dsp/lib/python3.13/site-packages/joblib/parallel.py:1783\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1777\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._wait_retrieval():\n\u001b[32m   1778\u001b[39m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[32m   1779\u001b[39m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[32m   1780\u001b[39m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[32m   1781\u001b[39m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[32m   1782\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._aborting:\n\u001b[32m-> \u001b[39m\u001b[32m1783\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1784\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1786\u001b[39m     nb_jobs = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._jobs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/Data Science Project/dsp/lib/python3.13/site-packages/joblib/parallel.py:1858\u001b[39m, in \u001b[36mParallel._raise_error_fast\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1854\u001b[39m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[32m   1855\u001b[39m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[32m   1856\u001b[39m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[32m   1857\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1858\u001b[39m     \u001b[43merror_job\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/Data Science Project/dsp/lib/python3.13/site-packages/joblib/parallel.py:757\u001b[39m, in \u001b[36mBatchCompletionCallBack.get_result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    751\u001b[39m backend = \u001b[38;5;28mself\u001b[39m.parallel._backend\n\u001b[32m    753\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m backend.supports_retrieve_callback:\n\u001b[32m    754\u001b[39m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[32m    755\u001b[39m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[32m    756\u001b[39m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m757\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    759\u001b[39m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[32m    760\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/Data Science Project/dsp/lib/python3.13/site-packages/joblib/parallel.py:772\u001b[39m, in \u001b[36mBatchCompletionCallBack._return_or_raise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    770\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    771\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.status == TASK_ERROR:\n\u001b[32m--> \u001b[39m\u001b[32m772\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n\u001b[32m    773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n\u001b[32m    774\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[31mValueError\u001b[39m: Shape mismatch: if categories is an array, it has to be of shape (n_features,)."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder,OrdinalEncoder\n",
    "from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from src.logger import logging\n",
    "\n",
    "logging.info('Proccess are ready to work')\n",
    "df = pd.read_csv('/Users/mac/Developer/Data Science Project/data/customer_training_dataset.csv',nrows=50000)\n",
    "df = df[['Age','Gender','Annual Income','Education Level','Location','Policy Type','Customer Feedback','Property Type','Premium Amount']]\n",
    "\n",
    "logging.info('data are load successfull.')\n",
    "\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "x = df.drop('Premium Amount',axis=1)\n",
    "y = df['Premium Amount']\n",
    "\n",
    "logging.info('spliting train and test.')\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "\n",
    "numerical_columns = ['Age',\n",
    "                     'Annual Income']\n",
    "\n",
    "categorical_columns = ['Gender',\n",
    "                       'Location',\n",
    "                       'Property Type']\n",
    "\n",
    "num_pipe = Pipeline(steps=[\n",
    "    ('impute',SimpleImputer(strategy='median')),\n",
    "    ('scaler',StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipe = Pipeline(steps=[\n",
    "    ('ipute',SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder',OneHotEncoder(handle_unknown='ignore',drop='first',sparse_output=False))\n",
    "])\n",
    "\n",
    "\n",
    "education_level_pipe = Pipeline(steps=[\n",
    "    ('impute',SimpleImputer(strategy='most_frequent')),\n",
    "    ('education_level_encode',OrdinalEncoder(categories=['Secondary Education','Undergraduate','Graduate','PhD']))\n",
    "])\n",
    "\n",
    "policy_type_pipe = Pipeline(steps=[\n",
    "    ('impute',SimpleImputer(strategy='most_frequent')),\n",
    "    ('policy_type_encode',OrdinalEncoder(categories=['Basic','Comprehensive','Premium']))\n",
    "])\n",
    "\n",
    "Customer_Feedback_pipe = Pipeline(steps=[\n",
    "    ('impute',SimpleImputer(strategy='most_frequent')),\n",
    "    ('Customer_Feedback_encode',OrdinalEncoder(categories=['Poor','Average','Good']))\n",
    "])\n",
    "\n",
    "transformer = ColumnTransformer(transformers=[\n",
    "    ('num_pipe',num_pipe,numerical_columns),\n",
    "    ('cat_pipe',cat_pipe,categorical_columns),\n",
    "    ('education_level_pipe',education_level_pipe,[3]),\n",
    "    ('policy_type_pipe',policy_type_pipe,[5]),\n",
    "    ('Customer_Feedback_pipe',Customer_Feedback_pipe,[6])\n",
    "],\n",
    "remainder='passthrough',\n",
    "n_jobs=-1)\n",
    "\n",
    "logging.info('transformation is going on.')\n",
    "\n",
    "transformer.fit(x_train)\n",
    "\n",
    "X_train = transformer.transform(x_train)\n",
    "X_test = transformer.transform(x_test)\n",
    "\n",
    "logging.info('transformation is done.')\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train,y_train)\n",
    "logging.info('model fit successfully.')\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "r2_s = r2_score(y_test,y_pred)\n",
    "mse = mean_squared_error(y_test,y_pred)\n",
    "mae = mean_absolute_error(y_test,y_pred)\n",
    "logging.info(f'all metrics are r2_score: {r2_s} - mean_squared_error: {mse} - mean_absolute_error: {mae}')\n",
    "\n",
    "print('OK')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f9ad65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
